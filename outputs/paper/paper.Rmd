---
title: "TBD"
subtitle: "TBD"
author: "Arjun Dhatt, Benjamin Draskovic, Yiqu Ding, Gantavya Gupta"
thanks: "Code and data are available at: https://github.com/STA304-PS4/Trump-vs-Biden."
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: |
  | First sentence. Second sentence. Third sentence. Fourth sentence. 
output:
  bookdown::pdf_document2:
toc: FALSE
bibliography: references.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
```

# Introduction


# Data

In this analysis, we collected data from the Nationscape dataset — a collaboration between the Democracy Fund Voter Study Group and UCLA Political Scientists. The Nationscape dataset that we will be analyzing was collected from June 25th, 2020 to July 1st, 2020. Using the data from Nationscape, we would like the predict the overall popular vote of the 2020 American presidential election using multilevel regression with post-stratification.  

The samples are provided by Lucid, “a market research platform that provides access to authentic, targeted audiences”. In order to ensure that an appropriate sample is selected, samples are selected based on a set of demographic quotas based on a multitude of factors such as age, gender, ethnicity, etc. Respondents of the survey are sent directly to an online survey (conducted in English) operated by the Nationscape team and forced to complete an attention check to ensure the answers they provide are meaningful. Lastly, the data is weighted to be representative of the American population using factors such as — gender, four major census regions, race, etc. 

The population in this dataset is all voting residents in the USA that are eligible to vote. This does not include a large population of those that reside in the US such as non-citizens or those who are incarcerated, but this is representative of a real election. The population frame is all voting residents in USA that have access to a computer in order to complete the online survey. As mentioned before, the survey is taken online, therefore it excludes those without access to a device that can take the online survey. The sample in this case is all respondents who complete this survey online. 

The data is collected using a convenience sample selected based on a set of demographic criteria. Because convenience sampling was used over random sampling, this can result in some biases in our dataset. 

The respondents of the survey are found through Lucid, which “runs an online exchange for survey respondents”. The respondents from the survey on Lucid are sent to the online Nationscape survey where they are prompted to complete the survey. Respondents who complete the survey not choose not to disclose their household income; this results in a large number of non-respondents because they may not be comfortable providing sensitive information. In an effort to account for the respondents who choose not to provide income, non-respondents are not weighed for income.  

The variables that we used in our dataset are as follow: 
-	age
     o	“What is your age”
     o	It provides an integer value greater than or equal to 18
-	education
     o	“What is the highest level of education you have completed?” 
     o	An extensive list of options are provided
-	Hispanic
     o	“Are you of Hispanic, Latino, or Spanish origin?” 
     o	An extensive list of options are provided 
-	household_income
     o	“What is your current annual household income before taxes? 
     o	Provides an extensive list of options beginning with $5,000 increments and then increases to $25,000 increments
     o	This is the variable in our dataset that many people did not feel comfortable answering and was left as N/A. When        cleaning the dataset, we removed all responses that left this answer as N/A  
-	race_ethnicity
     o	“What is your race”
     o	An extensive list of options are provided. 
-	extra_covid_worn_mask
     o	“Have you done any of the following in the past week? - Worn a mask when going out in public” 
     o	Yes or No options are available for the respondent to fill out 
-	state
     o	“Respondent’s state, as a two-character postal abbreviation. Calculated based on entered ZIP code.” 
     o	Manually filled out by respondent 
-	trump_biden
     o	“If the general election for president of the United States was a contest between Joe Biden and Donald Trump, who        would you support? “ 
     o	Options are either ‘Joe Biden’, ‘Donald Trump’, or ‘Don’t Know’ 

We also created another variable called ‘binary’ which outputs the result of the variable ‘trump_biden’ as a 1 or a 0 making it binary, therefore easier to analyze. 

Key features of data? 

The dataset we used contains many strengths and weaknesses. One of the strengths is due to the fact that the survey is distributed online. In today’s age where most things are online, this ensures that we can reach a wide part of the United States. At the same time, this can also be viewed as a weakness because certain age groups of the United States may not be tech-savvy enough to complete an online survey. The older population of the united states (e.g. 75+) may not be able to complete the survey because it is online which means that our data may not accurately reflect the older populations views regarding the 2020 election. A potential solution to this weakness is to use administer multiple forms of the survey to ensure that all people can access the survey.  

Another weakness of the data comes from the fact that we use convenience-based sampling which inherently contains bias. Because the sampling method is based on convenience, we may be unlucky when sampling and get a sample group that inaccurately represents the population of the US making our results meaningless. 

Lastly another weakness of our dataset is due to the fact that the survey data we are analyzing is collected from June 25th, 2020 to July 1st, 2020. Between July and November (the month of the election), many voters may not have an informed vote and their opinions may still be swayed after watching crucial debates and hearing what the leaders have to say; our data doesn’t take into consideration the people whose votes may change in the most crucial months of the election. A solution to this weakness can be to analyze data that may have occurred closer to the actual election so that the participants have an informed vote. 


# Model

The model we use to predict the result of the election is MRP, multilevel regression with post-stratification. The advantage of this model is that it has better performance when estimating behaviors of a particular subgroup of the population. One can interpret MRP as a combination of multilevel logistic regression and post-stratification. Logistic regression allows us the simplicity of analyzing the categorical response variable while incorporating both numerical and categorical explanatory variables; while combined with post-stratification, it yields a much narrower confidence interval for the estimation. 

We are interested in how variables such as age, education, race, family income, geographic region, and mask-wearing decision affect citizens’ voting intentions, particularly between the major party candidates, Donald Trump for the Republicans and Joe Biden for the Democratic Party. The response variable that we are interested in is the chances of a citizen voting for Trump in the coming presidential election. It is a categorical variable with two levels: 1 represents intending to vote for Donald Trump, and 2 means planning to vote for Joe Biden.

Ideally, we ought to run a pre-analysis to determine the variables of interest. However, we will leave that open for further analysis and future elections due to the limited time and budget. We chose the explanatory variables based on our understanding of a respondent’s significant characteristics that could potentially affect his/her voting intention. Except for respondents' age, education, income level, and state(common in statistical studies), we are very interested in the respondent's habits towards mask-wearing. Firstly because the US is the country with the most COVID cases globally, the influence of COVID on the electoral votes is inevitable. Secondly, since Trump and Biden hold quite opposites opinions towards handling the pandemic, this parameter will likely represent part of the respondent's voting intention in the same way as the more familiar political indicators. 

First, we train a multilevel logistic regression model using raw data from the voter study group towards the variable of interest using the seven explanatory variables. We then apply this model to our post-stratification data set to get the estimates.

Logistic regression estimates $\beta_0...\beta_k$ in  \@ref(eq:logistic)

\begin{equation}
log(\frac{p}{1-p})=\beta_0+\beta_1x_1+...+\beta_kx_k (\#eq:logistic)
\end{equation}

where p is the probability of event A that we are interested in, $\beta_0$is the intercept, $x_1...x_K$ are our variables of interest and $\beta_1...\beta_k$ are parameters for each of these variables. Based on the result, we are able to estimate p for a particular case given all the variables. We use `as.factors()` to incorporate dummy variables for all the categorical variable. 

The main logic behind post-stratification is that we divide the sample data into strata based on a few attributes such as state, income, education level. Then we come up with a weight for each stratum to adjust its influence towards our prediction. Namely, if a stratum is over-represented, we want to reduce its impact on the prediction result; if a stratum is under-represented, we want to increase its influence. In this sense, the combination with logistic regression allows subgroups with a relatively small size to 'reference' from other subgroups with similar characteristics.

To mimic the population as closely as possible, we need a post-stratification dataset large enough to refer to. In this report, we use the ACS(reason). 

The post-stratification estimate is defined by $\hat{y}_{PS} = \frac{\sum{N_j\hat{y}_j}}{\sum{N_j}}$ where $\hat{y}_j$ is the estimate of y in cell j, and $N_j$ is the size of the j-th cell in the population. An illustration using the education variable is $\hat{y}_{edu}^{PS} = \frac{\sum_{j\in J_{edu}}{N_j\hat{y}_j}}{\sum_{j\in J_{edu}}{N_j}}$, we can get an estimation given any level of education of respondents, $J_{edu}$ denotes all subsets of education levels, $\cup_{i\in J} J^{edu}_{i} =$ all possible education levels. 

\@ref(eq:logistic) produces a proportion for the post-stratification based on regression, instead of merely averaging the sample in each stratum. Specifically, all possible cells are determined from combining:

- 76 different ages;
- 11 education levels
- 15 races;
- 24 income levels;
- 51 states
- 2 options for mask wearing habits.

That is 

We fit the logistic regressions for estimating candidate support in each cell. We used `function` from `package` to fit \@ref(eq:model).

\begin{equation}
P(Trump) = logit^{-1}(
\beta_0 + \beta_age + \beta_{j[i]}^{edu} + \beta_{j[i]}^{race}
+ \beta_{j[i]}^{income} + \beta_{j[i]}^{state} + \beta_{j[i]}^{mask}
) (\#eq:model)
\end{equation}

\@ref(eq:model) is the model that we fit using the survey data, with $\beta_{j[i]}^{var} \sim N(0, \sigma^2_{var})$. 
$\beta_0$ is the intercept,each of $\beta_{j[i]}^{var}$ represents the parameter for the i-th respondent in j-th cell. For example, $\beta_{j[i]}^{state}$ can take values from $\beta$ for all states in the US. Then the model sums up estimates for each cell to the population. 

# Results

```{r, eval = FALSE}
fit <- brms::brm(
  binary ~ (1 | state) + (1 | age) + (1 | education) + (1 | household_income),
  family = bernoulli(link = "logit"),
  data = clean_survey
)
print(fit)
```

```{r, eval=FALSE}
# to get the estimated proportions and associated 95% PIs by state
res_state <- fit %>%
  add_predicted_draws(newdata=state_prop %>% 
                        filter(age_group>20, age_group<80, decade_married>1969),
                      allow_new_levels=TRUE) %>%
  rename(kept_name_predict = .prediction) %>% 
  mutate(kept_name_predict_prop = kept_name_predict*prop) %>% 
  group_by(state_name, .draw) %>% 
  summarise(kept_name_predict = sum(kept_name_predict_prop)) %>% 
  group_by(state_name) %>% 
  summarise(mean = mean(kept_name_predict), 
            lower = quantile(kept_name_predict, 0.025), 
            upper = quantile(kept_name_predict, 0.975))
```

```{r, eval=FALSE}
# graph by state
res_state %>% 
  arrange(-mean) %>% 
  left_join(d %>%
              group_by(state_name, kept_name) %>%
              summarise(n = n()) %>%
              group_by(state_name) %>%
              mutate(prop = n/sum(n)) %>%
              filter(kept_name==1)) %>% 
  ggplot(aes(y = mean, x = forcats::fct_inorder(state_name), color = "MRP estimate")) + 
  geom_point() +
  coord_flip() + 
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0) + 
  ylab("proportion keeping maiden name") + 
  xlab("state") + 
  geom_point(aes(state_name, prop, color = "raw data")) +
  scale_color_manual(name = "", values = c("MRP estimate" = "black", "raw data" = "red")) + 
  theme_bw() +
  ggtitle("Proportion of women keeping maiden name after marriage")


res_state %>% 
  mutate(statename = str_to_title(state_name)) %>% 
  #mutate(statename = ifelse(state_name=="district of columbia", "District of Columbia", statename)) %>% 
  ggplot(aes(fill = mean, state = statename)) + 
  geom_statebins() +
  scale_fill_viridis_c(name = "proportion keeping name") +
  theme_void()
ggsave("state_plot.png", width = 8, height = 6)
```

# Discussion

## First discussion point

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

### 1: Nested Bayesian Model

### 2: Pre-analysis

\newpage

# Appendix {-}

\newpage


# References


